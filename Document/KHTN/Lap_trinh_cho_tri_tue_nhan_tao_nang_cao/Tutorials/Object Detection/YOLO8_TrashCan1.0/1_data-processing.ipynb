{"cells":[{"cell_type":"markdown","metadata":{"id":"iXtD9mMLS_Fo"},"source":["# Trash Detection using YOLOv8\n","\n","## Part 1 - Data processing\n","\n","-------------------------------------\n","The [TrashCan (1.0)](https://conservancy.umn.edu/handle/11299/214865) dataset is composed of images annotated for detecting trash, ROVs, and flora & fauna on the ocean floors.\n","\n","<p align=\"center\">\n","  <img style=\"width: 300px\" src='https://learnopencv.com/wp-content/uploads/2022/11/annotated-trash-dataset-images-for-yolov6-custom-dataset-training.png' />\n","</p>\n","\n","This dataset is part of a research that also has an [accompanying technical article](https://arxiv.org/abs/2007.08097). It contains *7212* images with annotations, for instance, segmentation and bounding box detection. \n","\n","The **TrashCan dataset** contains two versions. They are:\n","- **TrashCan-Material**: Contains *16* different classes.\n","- **TrashCan-Instance**: Contains *22* different classes"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"jkA_5uUNW7tk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/SELab-Tutorials/Tutorial-YOLO"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A59NaAsGW4b4","executionInfo":{"status":"ok","timestamp":1676620320214,"user_tz":-420,"elapsed":384,"user":{"displayName":"Quang-Binh Nguyen","userId":"06350212682142861741"}},"outputId":"684a5c4c-0584-4a9b-ed02-79386f02601c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/SELab-Tutorials/Tutorial-YOLO\n"]}]},{"cell_type":"markdown","metadata":{"id":"RcVIFiVbS_Fr"},"source":["Firstly, let's download the [TrashCan 1.0](https://conservancy.umn.edu/bitstream/handle/11299/214865/dataset.zip?sequence=12&isAllowed=y) for Trash Detection problem\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P9PWBZsyS_Fs"},"outputs":[],"source":["# extract dataset\n","!unzip dataset.zip"]},{"cell_type":"markdown","metadata":{"id":"XiCDpVqKS_Ft"},"source":["After extracting, we have the structure directory as:"]},{"cell_type":"markdown","metadata":{"id":"dkoV0ElUS_Fu"},"source":["    .\n","    |-- README.txt\n","    |-- instance_version\n","    |   |-- README.txt\n","    |   |-- instances_train_trashcan.json\n","    |   |-- instances_val_trashcan.json\n","    |   |-- train\n","    |   `-- val\n","    |-- material_version\n","    |   |-- README.txt\n","    |   |-- instances_train_trashcan.json\n","    |   |-- instances_val_trashcan.json\n","    |   |-- train\n","    |   `-- val\n","    |-- original_data\n","    |   |-- README.txt\n","    |   |-- annotations\n","    |   `-- images\n","    `-- scripts\n","        `-- trash_can_coco.py"]},{"cell_type":"markdown","metadata":{"id":"LHY9BiYVS_Fu"},"source":["In this tutorial, we will be utilizing the **instance_version** of this dataset, which follows the COCO format. To use it, we need to convert it to the YOLO format."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZdNAyMu6S_Fv"},"outputs":[],"source":["import logging\n","logging.getLogger().setLevel(logging.CRITICAL)\n","!pip install pylabel > /dev/null\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jnPSqLnrS_Fw"},"outputs":[],"source":["from pylabel import importer\n","import os\n","import zipfile\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pOqXoCNES_Fw"},"outputs":[],"source":["def convert_to_YOLO_dataset(path_to_images=\"dataset/instance_version/train\", path_to_annotations=\"dataset/instance_version/instances_train_trashcan.json\", output_path='data/train/labels'):\n","    dataset = importer.ImportCoco(\n","        path_to_annotations, path_to_images=path_to_images)\n","\n","    dataset.path_to_annotations = path_to_annotations\n","    dataset.path_to_images = path_to_images\n","\n","    dataset.export.ExportToYoloV5(output_path)\n","\n","    return dataset\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OxvjoudGS_Fx","outputId":"b8503c7f-5662-4578-e49d-978271394d47"},"outputs":[{"name":"stderr","output_type":"stream","text":["Exporting files: 100%|██████████| 6065/6065 [00:10<00:00, 573.85it/s]\n","Exporting files: 100%|██████████| 1147/1147 [00:01<00:00, 700.24it/s]\n"]}],"source":["# train \n","train_data = convert_to_YOLO_dataset(path_to_images=\"dataset/instance_version/train\",\n","                        path_to_annotations=\"dataset/instance_version/instances_train_trashcan.json\",\n","                        output_path=\"datasets/data/train/labels\")\n","\n","!mkdir -p 'datasets/data/train/images'                        \n","!cp dataset/instance_version/train/* 'datasets/data/train/images'\n","\n","# val\n","val_data = convert_to_YOLO_dataset(path_to_images=\"dataset/instance_version/val\",\n","                        path_to_annotations=\"dataset/instance_version/instances_val_trashcan.json\",\n","                        output_path=\"datasets/data/val/labels\")\n","\n","!mkdir -p 'datasets/data/val/images'\n","!cp dataset/instance_version/val/* 'datasets/data/val/images'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G_qur2NaS_Fy"},"outputs":[],"source":["!rm datasets/data/train/dataset.yaml\n","!rm datasets/data/val/dataset.yaml\n","!touch datasets/dataset.yaml"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d5k4L6D_S_Fy"},"outputs":[],"source":["# Write the given content to a file\n","\n","filename = \"datasets/dataset.yaml\"\n","\n","content = \"# number of classes\\nnc: 22\\n\\n# class names\\nnames:\\n- rov\\n- plant\\n- animal_fish\\n- animal_starfish\\n- animal_shells\\n- animal_crab\\n- animal_eel\\n- animal_etc\\n- trash_clothing\\n- trash_pipe\\n- trash_bottle\\n- trash_bag\\n- trash_snack_wrapper\\n- trash_can\\n- trash_cup\\n- trash_container\\n- trash_unknown_instance\\n- trash_branch\\n- trash_wreckage\\n- trash_tarp\\n- trash_rope\\n- trash_net\\n\\n# Train/val dir\\npath: data\\ntrain: data/train/images\\nval: data/val/images\"\n","\n","with open(filename, \"w\") as file:\n","    file.write(content)\n"]},{"cell_type":"markdown","source":["And now, we have the dataset that in YOLO format"],"metadata":{"id":"8UxIr0EJTMJ_"}},{"cell_type":"code","source":["!tree -L 2 datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qoFtCaAGTQLG","executionInfo":{"status":"ok","timestamp":1676620461777,"user_tz":-420,"elapsed":355,"user":{"displayName":"Quang-Binh Nguyen","userId":"06350212682142861741"}},"outputId":"a5d2c466-f50c-4166-ec62-2427b7d47d92"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[01;34mdatasets\u001b[00m\n","├── \u001b[01;34mdata\u001b[00m\n","│   ├── \u001b[01;34mtrain\u001b[00m\n","│   └── \u001b[01;34mval\u001b[00m\n","└── data.yaml\n","\n","3 directories, 1 file\n"]}]},{"cell_type":"markdown","source":["Zip processed dataset to `trashcan-yolo.zip`"],"metadata":{"id":"YK6rP1HmXla8"}},{"cell_type":"code","source":["!zip -r trashcan-yolo.zip datasets"],"metadata":{"id":"cU9xWEThXiSr"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.7 ('pytorch-env')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"1e3c77405f6b92cedd960e026082f7f14d8b4fed8f60217ed1d135159ee803e3"}},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}